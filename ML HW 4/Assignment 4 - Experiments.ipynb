{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 4 - Simple Linear vs. Ridge Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the historical heart of Boston, Bob seeks to understand the intricacies of the real estate market. With a linear regression model at his side, Bob wonders if he can improve his predictions. Given your expertise in machine learning, he turns to you for guidance. Specifically, he wants to unravel the factors influencing the median value of homes across different Boston neighborhoods.\n",
    "\n",
    "To assist Bob, you decide to:\n",
    "*  Implement the closed-form solution for linear regression. \n",
    "* Apply a polynomial transformation to increase model flexibility.\n",
    "* Utilize ridge regression to control model complexity.\n",
    "* Apply 10-fold cross-validation for more reliable performance estimates.\n",
    "\n",
    "\n",
    "Bob is curious and wants to see a comparison between linear and ridge regression, both with and without polynomial transformations, on the same dataset. Thus, the challenge begins!\n",
    "\n",
    " Variables in order:\n",
    "* CRIM:     per capita crime rate by town\n",
    "*  ZN:       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "* INDUS:    proportion of non-retail business acres per town\n",
    "* CHAS:     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "* NOX:      nitric oxides concentration (parts per 10 million)\n",
    "* RM:       average number of rooms per dwelling\n",
    "* AGE:      proportion of owner-occupied units built prior to 1940\n",
    "* DIS:      weighted distances to five Boston employment centres\n",
    "* RAD:      index of accessibility to radial highways\n",
    "* TAX:      full-value property-tax rate per \\$10,000\n",
    "* PTRATIO:  pupil-teacher ratio by town\n",
    "* B:        $1000(Bk - 0.63)^2$ where Bk is the proportion of blacks by town\n",
    "* LSTAT:    \\% lower status of the population\n",
    "* MEDV:     Median value of owner-occupied homes in \\$1000's\n",
    "\n",
    "Note: The Boston Housing dataset, especially the 'B' variable, touches upon serious ethical and societal concerns related to race and inequality. Reflect upon these issues, and consider strategies such as excluding the 'B' column from analyses.\n",
    "\n",
    "With this context, let's assist Bob in his real estate endeavors!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Setup and Data Preparation\n",
    "Import Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Fundamental package for linear algebra and multidimensional arrays\n",
    "import pandas as pd  # Data analysis and manipulation tool\n",
    "\n",
    "# Transform features to polynomial features for model flexibility\n",
    "from sklearn.preprocessing import PolynomialFeatures  \n",
    "\n",
    "# Split arrays or matrices into random train and test subsets\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# Scale features to zero mean and unit variance, commonly used for normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Provides train/test indices to split data into train/test sets while performing cross-validation\n",
    "from sklearn.model_selection import KFold  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (506, 14)\n",
      "        0     1     2   3      4      5     6       7   8      9     10  \\\n",
      "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
      "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
      "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
      "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
      "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
      "\n",
      "       11    12    13  \n",
      "0  396.90  4.98  24.0  \n",
      "1  396.90  9.14  21.6  \n",
      "2  392.83  4.03  34.7  \n",
      "3  394.63  2.94  33.4  \n",
      "4  396.90  5.33  36.2  \n",
      "\n",
      "First 5 rows of X:\n",
      " [[6.3200e-03 1.8000e+01 2.3100e+00 0.0000e+00 5.3800e-01 6.5750e+00\n",
      "  6.5200e+01 4.0900e+00 1.0000e+00 2.9600e+02 1.5300e+01 3.9690e+02\n",
      "  4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 6.4210e+00\n",
      "  7.8900e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9690e+02\n",
      "  9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 7.1850e+00\n",
      "  6.1100e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9283e+02\n",
      "  4.0300e+00]\n",
      " [3.2370e-02 0.0000e+00 2.1800e+00 0.0000e+00 4.5800e-01 6.9980e+00\n",
      "  4.5800e+01 6.0622e+00 3.0000e+00 2.2200e+02 1.8700e+01 3.9463e+02\n",
      "  2.9400e+00]\n",
      " [6.9050e-02 0.0000e+00 2.1800e+00 0.0000e+00 4.5800e-01 7.1470e+00\n",
      "  5.4200e+01 6.0622e+00 3.0000e+00 2.2200e+02 1.8700e+01 3.9690e+02\n",
      "  5.3300e+00]]\n",
      "First 5 values of y:\n",
      " [[24. ]\n",
      " [21.6]\n",
      " [34.7]\n",
      " [33.4]\n",
      " [36.2]]\n",
      "X shape: (506, 13)\n",
      "y shape: (506, 1)\n"
     ]
    }
   ],
   "source": [
    "# Define feature names\n",
    "# Specifying the names of the columns in our dataset makes it easier to understand and reference them.\n",
    "feature_names = [\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"RAD\", \"PTRATIO\", \"B\", \"LSTAT\", \"MEDV\"]\n",
    "\n",
    "# Load the data\n",
    "# We read data from a CSV (Comma-Separated Values) file into a DataFrame. DataFrame is a 2D labeled data structure in pandas.\n",
    "filename = 'Boston_housing.csv'\n",
    "df = pd.read_csv(filename, sep='\\s+', header=None)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "# It's good practice to inspect the dataset's size and first few rows to ensure it's loaded correctly and understand its structure.\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# Extract features and target\n",
    "# Machine learning typically involves using features (independent variables) to predict a target (dependent variable).\n",
    "# Here, we separate the dataset into features (X) and target (y).\n",
    "X = np.array(df.iloc[:, :13])  # All columns up to the 13th are features\n",
    "y = np.array(df.iloc[:, 13]).reshape(-1, 1)  # The 13th column is our target, and we reshape it to a 2D array for compatibility.\n",
    "\n",
    "# Preview data\n",
    "# It's also good practice to preview the data after separation to ensure everything looks as expected.\n",
    "print(\"\\nFirst 5 rows of X:\\n\", X[:5])\n",
    "print(\"First 5 values of y:\\n\", y[:5])\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing values\n",
    "\n",
    "After getting the data, it's always a good practice to check for missing values in the dataset. Luckily for us, this dataset has no missing values. Here's how you can verify that:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X: 0\n",
      "Missing values in y: 0\n"
     ]
    }
   ],
   "source": [
    "# 2. Check for Missing Values:\n",
    "print(\"Missing values in X:\", np.isnan(X).sum())\n",
    "print(\"Missing values in y:\", np.isnan(y).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing 10-Fold Cross-Validation\n",
    "With the data now loaded into X and y, your next task is to implement the code to select the optimal regularization and polynomial transformation. Utilize 10-fold cross-validation to assess the various configurations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Fold Cross-Validation with Feature Scaling and Polynomial Transformation\n",
    "\n",
    "Cross-validation is a method to assess the performance of a machine learning model on unseen data by dividing the data into a set number of groups, or \"folds\".\n",
    "\n",
    "### Why 10-Fold Cross-Validation?\n",
    "\n",
    "In 10-fold cross-validation, the dataset is randomly divided into ten parts or folds. The idea is to iteratively train the model on 9 of these folds and test it on the tenth. This is done ten times, once for each fold acting as the validation set. By doing so, we're ensuring that each data point gets to be in a validation set exactly once.\n",
    "\n",
    "### Feature Scaling Within Cross-Validation\n",
    "\n",
    "Feature scaling ensures that all features contribute equally to the model performance, which is particularly important for algorithms sensitive to feature magnitudes.\n",
    "\n",
    "When doing cross-validation, it's crucial that we don't introduce data leakage by scaling using statistics from the entire dataset. Instead:\n",
    "1. Divide the data into training and validation sets.\n",
    "2. Fit the scaler on the training set.\n",
    "3. Apply the scaling to both the training and validation sets using this scaler.\n",
    "\n",
    "### Polynomial Transformation Within Cross-Validation\n",
    "\n",
    "Polynomial transformations capture more intricate data relationships by adding polynomial features. Here's how you incorporate it into cross-validation:\n",
    "1. Divide the data into training and validation sets.\n",
    "2. Fit the polynomial transformer on the training set.\n",
    "3. Transform both the training and validation sets using this transformer.\n",
    "4. Fit the scaler on the transformed training set\n",
    "4. Apply the scaling to both the transformed training and transformed validation sets using this scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Note on Cross-Validation Error Calculation\n",
    "\n",
    "In most lecture notes and literature on k-fold cross-validation, the procedure for calculating the cross-validation error typically involves computing the mean of the errors obtained from each fold. However, in the context of our analysis, given the relatively small size of the dataset and the possibility of unequal numbers of samples in each fold, this traditional approach might not be mathematically rigorous.\n",
    "\n",
    "To address this, our approach for calculating the cross-validation error will deviate slightly from the traditional method. Instead of merely averaging the errors from each fold, we will sum up the errors across all folds and then divide by $ N $, the total number of training examples. This ensures that our error estimate is unbiased and takes into account the potential discrepancy in the number of samples across different folds.\n",
    "\n",
    "Mathematically, the cross-validation error, $ E_{cv} $, for this assignment is computed as:\n",
    "$$  E_{\\text{cv}} = \\frac{1}{N} \\sum_{i=1}^{k} \\sum_{j \\in \\text{fold } i} (y^{(j)}- \\hat{y}^{(j)})^2\n",
    " $$\n",
    "where $ k $ is the number of folds, $ y^{(j)} $ is the true target value of the $j^{th} $ example, and $ \\hat{y}^{(j)} $ is the predicted value for the same example.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your code goes here\n",
    "\n",
    "Feel free to add any helper functions you may need.\n",
    "\n",
    "### Part a) 5-fold Cross Validation using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y):\n",
    "    # use np.linalg.pinv(a)    \n",
    "    # Compute the weights using the closed-form solution \n",
    "    #### TO-DO #####\n",
    "    w = np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "    \n",
    "    \n",
    "    ##############\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next implement Squared Error. It measures the average squared difference between the estimated values (predictions) and the actual values (true values). Mathematically, it is represented as: $  \\sum_{i=1}^{N} (y^{(i)} - \\hat{y}^{(i)})^2 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error(y_true, y_pred):    \n",
    "    #### TO-DO ##### \n",
    "    # Calculate the squared differences\n",
    "    error = (y_true - y_pred) ** 2\n",
    "\n",
    "\n",
    "    ##############    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_linear_regression(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation for linear regression.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, random_state=10, shuffle=True)\n",
    "    #### TO-DO #####\n",
    "    \n",
    "    e_in = []\n",
    "    e_cv = []\n",
    "    \n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        X_train_with_ones_column = np.append(np.ones([len(X_train),1]),X_train,1)\n",
    "        \n",
    "        w = linear_regression(X_train_with_ones_column, y_train)\n",
    "        \n",
    "        y_pred = X_train_with_ones_column @ w\n",
    "        \n",
    "        in_sample_error = squared_error(y_train, y_pred)\n",
    "        total_in_sample_error_per_fold = np.sum(in_sample_error,0)\n",
    "        e_in.append(total_in_sample_error_per_fold)\n",
    "        \n",
    "        X_val_with_ones_column = np.append(np.ones([len(X_val),1]),X_val,1)\n",
    "        \n",
    "        y_pred_val = X_val_with_ones_column @ w\n",
    "        \n",
    "        cross_validation_error = squared_error(y_val, y_pred_val)\n",
    "        total_cross_validation_error_per_fold = np.sum(cross_validation_error,0)\n",
    "        e_cv.append(total_cross_validation_error_per_fold)\n",
    "\n",
    "        # Fit the model on training data\n",
    "        \n",
    "        \n",
    "        # Calculate in-sample error and cross-validation error\n",
    "\n",
    "        \n",
    "    ##############\n",
    "    overall_in_sample_error = 0\n",
    "    for e in e_in:\n",
    "        overall_in_sample_error += e\n",
    "    \n",
    "    average_in_sample_error = overall_in_sample_error / (len(X) * (k-1)) \n",
    "    \n",
    "    overall_cross_validation_error = 0\n",
    "    for e in e_cv:\n",
    "        overall_cross_validation_error += e\n",
    "    final_cv = overall_cross_validation_error/len(X)\n",
    "    \n",
    "    return average_in_sample_error, final_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For part a)\n",
      "Average in-sample error using 10-cross-fold validation with linear regression =  21.799517678658443\n",
      "Cross-Validation error =  23.75533358955554\n"
     ]
    }
   ],
   "source": [
    "e_in, e_cv = k_fold_linear_regression(X,y)\n",
    "print(\"For part a)\")\n",
    "print(\"Average in-sample error using 10-cross-fold validation with linear regression = \", e_in[0])\n",
    "print(\"Cross-Validation error = \", e_cv[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.79951768] [23.75533359]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "e_in_scaled, e_cv_scaled = k_fold_linear_regression(X_scaled, y)\n",
    "\n",
    "print(e_in_scaled, e_cv_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b) Adding Ridge Regression\n",
    "Enhance the previous code to include Ridge Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X, y, alpha):\n",
    "    # use np.linalg.pinv(a)    \n",
    "    # Compute the weights using the closed-form solution \n",
    "    #### TO-DO #####\n",
    "    identity_matrix = np.identity(X.shape[1])\n",
    "    identity_matrix[0,0] = 0\n",
    "    \n",
    "    w = np.linalg.pinv(X.T @ X + len(y)*alpha*identity_matrix) @ X.T @ y\n",
    "    \n",
    "    ##############\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def k_fold_ridge_regression(X, y, k=10, lambdas=np.logspace(-5,1,num=15)):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation for ridge regression with various lambda values.\n",
    "    \"\"\"\n",
    "    best_alpha = None\n",
    "    best_error = float('inf')\n",
    "    \n",
    "    kf = KFold(n_splits=k, random_state=10, shuffle=True)\n",
    "    \n",
    "    for alpha in lambdas:\n",
    "    #### TO-DO #####\n",
    "        e_in = []\n",
    "        e_cv = []\n",
    "\n",
    "\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "            X_train_with_ones_column = np.append(np.ones([len(X_train),1]),X_train,1)\n",
    "\n",
    "            w = ridge_regression(X_train_with_ones_column, y_train, alpha)\n",
    "\n",
    "            y_pred = X_train_with_ones_column @ w\n",
    "\n",
    "            in_sample_error = squared_error(y_train, y_pred)\n",
    "            total_in_sample_error_per_fold = np.sum(in_sample_error,0)\n",
    "            e_in.append(total_in_sample_error_per_fold)\n",
    "\n",
    "            X_val_with_ones_column = np.append(np.ones([len(X_val),1]),X_val,1)\n",
    "\n",
    "            y_pred_val = X_val_with_ones_column @ w\n",
    "\n",
    "            cross_validation_error = squared_error(y_val, y_pred_val)\n",
    "            total_cross_validation_error_per_fold = np.sum(cross_validation_error,0)\n",
    "            e_cv.append(total_cross_validation_error_per_fold)\n",
    "        \n",
    "        overall_in_sample_error = 0\n",
    "        for e in e_in:\n",
    "            overall_in_sample_error += e\n",
    "\n",
    "        average_in_sample_error = overall_in_sample_error / (len(X) * (k-1)) \n",
    "\n",
    "        overall_cross_validation_error = 0\n",
    "        for e in e_cv:\n",
    "            overall_cross_validation_error += e\n",
    "        final_cv = overall_cross_validation_error/len(X)\n",
    "        \n",
    "        print(\"for alpha (lambda) = \", alpha)\n",
    "        print(\"Average in-sample error = \", average_in_sample_error)\n",
    "        print(\"Cross-validation error = \", final_cv)\n",
    "        print(\"----------------------------------------------------------\")\n",
    "        \n",
    "        if final_cv < best_error:\n",
    "            best_error = final_cv\n",
    "            best_alpha = alpha\n",
    "    \n",
    "            \n",
    "    ##############\n",
    "    return best_alpha, best_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part b) Average in-sample errors and cross-validation errors for different values of alpha (lambda) - \n",
      "for alpha (lambda) =  1e-05\n",
      "Average in-sample error =  [21.79951771]\n",
      "Cross-validation error =  [23.75528201]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  2.6826957952797274e-05\n",
      "Average in-sample error =  [21.79951788]\n",
      "Cross-validation error =  [23.75519536]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  7.196856730011514e-05\n",
      "Average in-sample error =  [21.79951912]\n",
      "Cross-validation error =  [23.7549638]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.00019306977288832496\n",
      "Average in-sample error =  [21.79952801]\n",
      "Cross-validation error =  [23.754349]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.0005179474679231213\n",
      "Average in-sample error =  [21.79959149]\n",
      "Cross-validation error =  [23.75274536]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.0013894954943731374\n",
      "Average in-sample error =  [21.80003816]\n",
      "Cross-validation error =  [23.74876207]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.003727593720314938\n",
      "Average in-sample error =  [21.8030704]\n",
      "Cross-validation error =  [23.74019573]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.01\n",
      "Average in-sample error =  [21.82193944]\n",
      "Cross-validation error =  [23.72970147]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.026826957952797246\n",
      "Average in-sample error =  [21.91990611]\n",
      "Cross-validation error =  [23.75796269]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.07196856730011514\n",
      "Average in-sample error =  [22.30484025]\n",
      "Cross-validation error =  [23.99497674]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.19306977288832497\n",
      "Average in-sample error =  [23.47115187]\n",
      "Cross-validation error =  [24.91190893]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.5179474679231213\n",
      "Average in-sample error =  [26.57890012]\n",
      "Cross-validation error =  [27.74993258]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  1.389495494373136\n",
      "Average in-sample error =  [33.64388348]\n",
      "Cross-validation error =  [34.65230145]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  3.727593720314938\n",
      "Average in-sample error =  [45.24613301]\n",
      "Cross-validation error =  [46.16413037]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  10.0\n",
      "Average in-sample error =  [59.21290918]\n",
      "Cross-validation error =  [60.03627964]\n",
      "----------------------------------------------------------\n",
      "The best cross-validation error was obtained when alpha = 0.01.\n",
      "The cross-validation error in this case is -  [23.72970147]\n"
     ]
    }
   ],
   "source": [
    "#Use your code to answer question b)    \n",
    "#### TO-DO #####\n",
    "print(\"Part b) Average in-sample errors and cross-validation errors for different values of alpha (lambda) - \")\n",
    "best_alpha , best_error = k_fold_ridge_regression(X_scaled, y)\n",
    "\n",
    "print(\"The best cross-validation error was obtained when alpha = \" + str(best_alpha) + \".\")\n",
    "print(\"The cross-validation error in this case is - \", best_error)\n",
    "    \n",
    "##############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c) Adding Polynomial Transformations and Ridge Regression\n",
    "Extend their code to incorporate polynomial transformations combined with Ridge Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def k_fold_poly_ridge(X, y, k=10, lambdas=np.logspace(-5,1,num=15), degrees=[1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation for ridge regression with various lambda values and polynomial transformations.\n",
    "    \"\"\"\n",
    "    best_lambda = None\n",
    "    best_degree = None\n",
    "    best_error = float('inf')\n",
    "    \n",
    "    kf = KFold(n_splits=k, random_state=10, shuffle=True)\n",
    "    \n",
    "    for degree in degrees:\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        X_poly = poly.fit_transform(X)\n",
    "        for alpha in lambdas:\n",
    "            e_in = []\n",
    "            e_cv = []\n",
    "\n",
    "\n",
    "            for train_index, val_index in kf.split(X_poly):\n",
    "                X_train, X_val = X_poly[train_index], X_poly[val_index]\n",
    "                y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "                w = ridge_regression(X_train, y_train, alpha)\n",
    "\n",
    "                y_pred = X_train @ w\n",
    "\n",
    "                in_sample_error = squared_error(y_train, y_pred)\n",
    "                total_in_sample_error_per_fold = np.sum(in_sample_error,0)\n",
    "                e_in.append(total_in_sample_error_per_fold)\n",
    "\n",
    "                y_pred_val = X_val @ w\n",
    "\n",
    "                cross_validation_error = squared_error(y_val, y_pred_val)\n",
    "                total_cross_validation_error_per_fold = np.sum(cross_validation_error,0)\n",
    "                e_cv.append(total_cross_validation_error_per_fold)\n",
    "\n",
    "            overall_in_sample_error = 0\n",
    "            for e in e_in:\n",
    "                overall_in_sample_error += e\n",
    "\n",
    "            average_in_sample_error = overall_in_sample_error / (len(y) * (k-1)) \n",
    "\n",
    "            overall_cross_validation_error = 0\n",
    "            for e in e_cv:\n",
    "                overall_cross_validation_error += e\n",
    "            final_cv = overall_cross_validation_error/len(y)\n",
    "\n",
    "            print(\"for alpha (lambda) = \", alpha, \"and degree = \", degree)\n",
    "            print(\"Average in-sample error = \", average_in_sample_error)\n",
    "            print(\"Cross-validation error = \", final_cv)\n",
    "            print(\"----------------------------------------------------------\")\n",
    "            \n",
    "            \n",
    "    #### TO-DO #####\n",
    "            if final_cv < best_error:\n",
    "                best_error = final_cv\n",
    "                best_lambda = alpha\n",
    "                best_degree = degree\n",
    "    \n",
    "    \n",
    "    return best_lambda, best_degree, best_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part c) and d) Average in-sample errors and cross-validation errors for different values of alpha (lambda) and degrees - \n",
      "for alpha (lambda) =  1e-05 and degree =  1\n",
      "Average in-sample error =  [21.79951771]\n",
      "Cross-validation error =  [23.75528201]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  2.6826957952797274e-05 and degree =  1\n",
      "Average in-sample error =  [21.79951788]\n",
      "Cross-validation error =  [23.75519536]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  7.196856730011514e-05 and degree =  1\n",
      "Average in-sample error =  [21.79951912]\n",
      "Cross-validation error =  [23.7549638]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.00019306977288832496 and degree =  1\n",
      "Average in-sample error =  [21.79952801]\n",
      "Cross-validation error =  [23.754349]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.0005179474679231213 and degree =  1\n",
      "Average in-sample error =  [21.79959149]\n",
      "Cross-validation error =  [23.75274536]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.0013894954943731374 and degree =  1\n",
      "Average in-sample error =  [21.80003816]\n",
      "Cross-validation error =  [23.74876207]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.003727593720314938 and degree =  1\n",
      "Average in-sample error =  [21.8030704]\n",
      "Cross-validation error =  [23.74019573]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.01 and degree =  1\n",
      "Average in-sample error =  [21.82193944]\n",
      "Cross-validation error =  [23.72970147]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.026826957952797246 and degree =  1\n",
      "Average in-sample error =  [21.91990611]\n",
      "Cross-validation error =  [23.75796269]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.07196856730011514 and degree =  1\n",
      "Average in-sample error =  [22.30484025]\n",
      "Cross-validation error =  [23.99497674]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.19306977288832497 and degree =  1\n",
      "Average in-sample error =  [23.47115187]\n",
      "Cross-validation error =  [24.91190893]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.5179474679231213 and degree =  1\n",
      "Average in-sample error =  [26.57890012]\n",
      "Cross-validation error =  [27.74993258]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  1.389495494373136 and degree =  1\n",
      "Average in-sample error =  [33.64388348]\n",
      "Cross-validation error =  [34.65230145]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  3.727593720314938 and degree =  1\n",
      "Average in-sample error =  [45.24613301]\n",
      "Cross-validation error =  [46.16413037]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  10.0 and degree =  1\n",
      "Average in-sample error =  [59.21290918]\n",
      "Cross-validation error =  [60.03627964]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  1e-05 and degree =  2\n",
      "Average in-sample error =  [5.75443095]\n",
      "Cross-validation error =  [14.18236299]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  2.6826957952797274e-05 and degree =  2\n",
      "Average in-sample error =  [5.76043295]\n",
      "Cross-validation error =  [14.16343768]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  7.196856730011514e-05 and degree =  2\n",
      "Average in-sample error =  [5.76751291]\n",
      "Cross-validation error =  [14.10973676]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.00019306977288832496 and degree =  2\n",
      "Average in-sample error =  [5.78202744]\n",
      "Cross-validation error =  [13.97801277]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.0005179474679231213 and degree =  2\n",
      "Average in-sample error =  [5.81742184]\n",
      "Cross-validation error =  [13.69511739]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.0013894954943731374 and degree =  2\n",
      "Average in-sample error =  [5.89270387]\n",
      "Cross-validation error =  [13.1925722]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.003727593720314938 and degree =  2\n",
      "Average in-sample error =  [6.04141945]\n",
      "Cross-validation error =  [12.52986224]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.01 and degree =  2\n",
      "Average in-sample error =  [6.34456333]\n",
      "Cross-validation error =  [11.97700863]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.026826957952797246 and degree =  2\n",
      "Average in-sample error =  [6.91545912]\n",
      "Cross-validation error =  [11.80312397]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.07196856730011514 and degree =  2\n",
      "Average in-sample error =  [7.86582935]\n",
      "Cross-validation error =  [12.16935452]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.19306977288832497 and degree =  2\n",
      "Average in-sample error =  [9.57424631]\n",
      "Cross-validation error =  [13.53602487]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.5179474679231213 and degree =  2\n",
      "Average in-sample error =  [12.97480609]\n",
      "Cross-validation error =  [16.71010986]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  1.389495494373136 and degree =  2\n",
      "Average in-sample error =  [18.94575992]\n",
      "Cross-validation error =  [22.23267886]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  3.727593720314938 and degree =  2\n",
      "Average in-sample error =  [28.26894021]\n",
      "Cross-validation error =  [31.03223955]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  10.0 and degree =  2\n",
      "Average in-sample error =  [41.61020956]\n",
      "Cross-validation error =  [43.92666333]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  1e-05 and degree =  3\n",
      "Average in-sample error =  [0.40684878]\n",
      "Cross-validation error =  [548.80696781]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  2.6826957952797274e-05 and degree =  3\n",
      "Average in-sample error =  [0.50380314]\n",
      "Cross-validation error =  [397.18133051]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  7.196856730011514e-05 and degree =  3\n",
      "Average in-sample error =  [0.62347984]\n",
      "Cross-validation error =  [306.53212991]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.00019306977288832496 and degree =  3\n",
      "Average in-sample error =  [0.77059453]\n",
      "Cross-validation error =  [270.83425379]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.0005179474679231213 and degree =  3\n",
      "Average in-sample error =  [0.96747945]\n",
      "Cross-validation error =  [241.71768779]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.0013894954943731374 and degree =  3\n",
      "Average in-sample error =  [1.25639603]\n",
      "Cross-validation error =  [177.22814515]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.003727593720314938 and degree =  3\n",
      "Average in-sample error =  [1.67847985]\n",
      "Cross-validation error =  [96.13277677]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.01 and degree =  3\n",
      "Average in-sample error =  [2.25439495]\n",
      "Cross-validation error =  [42.82920298]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.026826957952797246 and degree =  3\n",
      "Average in-sample error =  [3.00590385]\n",
      "Cross-validation error =  [20.55363256]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.07196856730011514 and degree =  3\n",
      "Average in-sample error =  [3.95080391]\n",
      "Cross-validation error =  [13.11628128]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.19306977288832497 and degree =  3\n",
      "Average in-sample error =  [5.04683739]\n",
      "Cross-validation error =  [11.4902794]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  0.5179474679231213 and degree =  3\n",
      "Average in-sample error =  [6.3535949]\n",
      "Cross-validation error =  [12.44535375]\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for alpha (lambda) =  1.389495494373136 and degree =  3\n",
      "Average in-sample error =  [8.40060909]\n",
      "Cross-validation error =  [14.92261159]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  3.727593720314938 and degree =  3\n",
      "Average in-sample error =  [12.18049226]\n",
      "Cross-validation error =  [18.90536649]\n",
      "----------------------------------------------------------\n",
      "for alpha (lambda) =  10.0 and degree =  3\n",
      "Average in-sample error =  [18.31240598]\n",
      "Cross-validation error =  [24.47361426]\n",
      "----------------------------------------------------------\n",
      "The best cross-validation error was obtained when alpha =  0.19306977288832497 and degree =  3\n",
      "The cross-validation error in this case is -  [11.4902794]\n"
     ]
    }
   ],
   "source": [
    "#Use your code to answer question b)    \n",
    "#### TO-DO #####\n",
    "print(\"Part c) and d) Average in-sample errors and cross-validation errors for different values of alpha (lambda) and degrees - \")\n",
    "best_lambda, best_degree, best_error = k_fold_poly_ridge(X_scaled, y)\n",
    "\n",
    "print(\"The best cross-validation error was obtained when alpha = \", best_lambda, \"and degree = \", best_degree)\n",
    "print(\"The cross-validation error in this case is - \", best_error)\n",
    "    \n",
    "##############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and Responses\n",
    "### Calculation for part b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "feature_values = [1,0.1,11,7,0,0.4,6,70,4,6,300,16,360,10]\n",
    "print(len(feature_values))\n",
    "best_alpha = 0.19306977288832497\n",
    "best_degree = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the ridge regression model with alpha = 0.01 (Not using the poly_ridge_function as best degree = 1)\n",
    "def best_k_fold_poly_ridge(X, y, k=10, alpha = 0.19306977288832497, degrees = 3):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation for ridge regression with various lambda values and polynomial transformations.\n",
    "    \"\"\"\n",
    "    best_lambda = None\n",
    "    best_degree = None\n",
    "    best_error = float('inf')\n",
    "    \n",
    "    kf = KFold(n_splits=k, random_state=10, shuffle=True)\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=degrees)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    e_in = []\n",
    "    e_cv = []\n",
    "\n",
    "\n",
    "    for train_index, val_index in kf.split(X_poly):\n",
    "        X_train, X_val = X_poly[train_index], X_poly[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        w = ridge_regression(X_train, y_train, alpha)\n",
    "\n",
    "        y_pred = X_train @ w\n",
    "\n",
    "        in_sample_error = squared_error(y_train, y_pred)\n",
    "        total_in_sample_error_per_fold = np.sum(in_sample_error,0)\n",
    "        e_in.append(total_in_sample_error_per_fold)\n",
    "\n",
    "        y_pred_val = X_val @ w\n",
    "\n",
    "        cross_validation_error = squared_error(y_val, y_pred_val)\n",
    "        total_cross_validation_error_per_fold = np.sum(cross_validation_error,0)\n",
    "        e_cv.append(total_cross_validation_error_per_fold)\n",
    "\n",
    "    overall_in_sample_error = 0\n",
    "    for e in e_in:\n",
    "        overall_in_sample_error += e\n",
    "\n",
    "    average_in_sample_error = overall_in_sample_error / (len(y) * (k-1)) \n",
    "\n",
    "    overall_cross_validation_error = 0\n",
    "    for e in e_cv:\n",
    "        overall_cross_validation_error += e\n",
    "    final_cv = overall_cross_validation_error/len(y)\n",
    "\n",
    "    print(\"for alpha (lambda) = \", alpha, \"and degree = \", degrees)\n",
    "    print(\"Average in-sample error = \", average_in_sample_error)\n",
    "    print(\"Cross-validation error = \", final_cv)\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for alpha (lambda) =  0.19306977288832497 and degree =  3\n",
      "Average in-sample error =  [5.04683739]\n",
      "Cross-validation error =  [11.4902794]\n",
      "----------------------------------------------------------\n",
      "[[ 2.13960140e+01]\n",
      " [-4.69212400e-02]\n",
      " [ 5.23590246e-02]\n",
      " [-5.20811270e-02]\n",
      " [ 5.64785355e-03]\n",
      " [-1.02072567e-01]\n",
      " [ 7.32478263e-01]\n",
      " [-4.34884173e-01]\n",
      " [-1.38508352e-01]\n",
      " [ 1.65249451e-01]\n",
      " [-1.01231207e-01]\n",
      " [-2.95172037e-01]\n",
      " [ 8.07574028e-02]\n",
      " [-4.85157234e-01]\n",
      " [ 3.33692859e-02]\n",
      " [ 2.24194676e-03]\n",
      " [-9.99041331e-03]\n",
      " [ 6.97589259e-02]\n",
      " [-2.47886280e-02]\n",
      " [-3.01943672e-01]\n",
      " [ 1.13611679e-01]\n",
      " [ 6.15319745e-02]\n",
      " [-9.68226162e-02]\n",
      " [ 1.00918239e-02]\n",
      " [ 9.04887919e-02]\n",
      " [-3.23249848e-02]\n",
      " [ 8.52696009e-02]\n",
      " [-1.47803307e-02]\n",
      " [-3.05948638e-02]\n",
      " [-3.04361882e-02]\n",
      " [ 5.45532205e-02]\n",
      " [-1.68503529e-01]\n",
      " [ 4.73122389e-02]\n",
      " [ 3.28900991e-02]\n",
      " [-9.33804043e-02]\n",
      " [ 1.04111161e-01]\n",
      " [ 5.54231911e-02]\n",
      " [-1.35381906e-02]\n",
      " [ 1.92336624e-01]\n",
      " [ 2.10315666e-01]\n",
      " [ 2.15809702e-02]\n",
      " [-3.12746830e-02]\n",
      " [-2.53176587e-01]\n",
      " [ 3.57357788e-02]\n",
      " [ 1.68120382e-01]\n",
      " [-9.99563420e-02]\n",
      " [ 1.79887011e-01]\n",
      " [ 2.91208590e-02]\n",
      " [ 1.35866246e-03]\n",
      " [-1.49709234e-01]\n",
      " [ 1.91789771e-02]\n",
      " [-2.15058846e-02]\n",
      " [-2.22407804e-01]\n",
      " [ 1.19379615e-01]\n",
      " [-7.78380210e-03]\n",
      " [-1.23762335e-02]\n",
      " [ 4.38906340e-02]\n",
      " [ 1.09008416e-01]\n",
      " [-3.92914663e-02]\n",
      " [ 9.15918757e-02]\n",
      " [-9.36005410e-02]\n",
      " [-2.53640266e-01]\n",
      " [-6.22244798e-03]\n",
      " [ 1.51784127e-01]\n",
      " [-6.82770589e-02]\n",
      " [ 4.00136403e-02]\n",
      " [-3.86189879e-02]\n",
      " [-5.50177751e-02]\n",
      " [ 3.87694467e-02]\n",
      " [ 3.96017945e-01]\n",
      " [-2.44623449e-01]\n",
      " [ 1.17405248e-01]\n",
      " [-3.51882903e-01]\n",
      " [-4.38733941e-01]\n",
      " [-2.27605308e-01]\n",
      " [ 1.98175263e-01]\n",
      " [-5.75832511e-01]\n",
      " [ 2.13586726e-02]\n",
      " [ 5.60382661e-02]\n",
      " [ 1.44640045e-01]\n",
      " [ 7.78025467e-02]\n",
      " [-1.17656849e-01]\n",
      " [-1.49447152e-01]\n",
      " [-1.96339718e-01]\n",
      " [ 4.03499038e-02]\n",
      " [ 2.85597102e-02]\n",
      " [ 1.09016185e-01]\n",
      " [-2.72903595e-02]\n",
      " [-4.79531785e-02]\n",
      " [ 2.62218036e-01]\n",
      " [-2.02107461e-01]\n",
      " [-3.90188220e-02]\n",
      " [ 1.14029700e-01]\n",
      " [ 2.89010435e-02]\n",
      " [-1.41682005e-01]\n",
      " [ 2.42159169e-01]\n",
      " [ 2.68698385e-01]\n",
      " [-2.52319288e-02]\n",
      " [-8.03220279e-02]\n",
      " [ 2.16689458e-02]\n",
      " [-3.61273319e-02]\n",
      " [ 3.52345315e-02]\n",
      " [-7.48719715e-02]\n",
      " [-4.48222520e-02]\n",
      " [ 4.59221222e-01]\n",
      " [ 1.67860899e-04]\n",
      " [-8.28225679e-03]\n",
      " [ 1.79038556e-02]\n",
      " [ 2.56721949e-02]\n",
      " [ 2.51943394e-02]\n",
      " [ 1.29319294e-02]\n",
      " [-1.18802767e-01]\n",
      " [-6.33428802e-02]\n",
      " [ 5.87891920e-02]\n",
      " [ 1.45955369e-02]\n",
      " [-2.23015762e-02]\n",
      " [-3.45503150e-02]\n",
      " [ 2.68339779e-02]\n",
      " [-2.68714611e-03]\n",
      " [ 2.74662273e-02]\n",
      " [-2.25314462e-02]\n",
      " [ 7.93123534e-03]\n",
      " [ 6.60264393e-02]\n",
      " [ 8.81584549e-03]\n",
      " [-1.38121132e-02]\n",
      " [ 5.19934369e-02]\n",
      " [-2.70533595e-02]\n",
      " [-6.47438587e-03]\n",
      " [ 5.23325018e-03]\n",
      " [-2.37154494e-02]\n",
      " [-1.18861828e-01]\n",
      " [ 6.15418300e-02]\n",
      " [-5.15524909e-02]\n",
      " [ 7.30368151e-02]\n",
      " [-6.71282390e-02]\n",
      " [-7.05853759e-02]\n",
      " [-6.12710107e-03]\n",
      " [-1.18727275e-01]\n",
      " [-2.55527391e-02]\n",
      " [-9.23366328e-03]\n",
      " [-3.31530365e-02]\n",
      " [ 1.89966071e-01]\n",
      " [ 3.02764118e-02]\n",
      " [ 3.96355052e-02]\n",
      " [ 3.54551541e-02]\n",
      " [-1.21757672e-01]\n",
      " [ 1.12005271e-01]\n",
      " [ 8.25412203e-02]\n",
      " [ 1.12373455e-02]\n",
      " [-8.52593762e-03]\n",
      " [-7.45389100e-02]\n",
      " [-1.23607483e-02]\n",
      " [ 5.81915828e-02]\n",
      " [-7.56944955e-02]\n",
      " [-6.42903348e-03]\n",
      " [-6.50154883e-02]\n",
      " [-1.04156492e-01]\n",
      " [-1.81246913e-02]\n",
      " [-1.86800231e-02]\n",
      " [-6.47762916e-02]\n",
      " [ 4.63643989e-02]\n",
      " [-3.71441225e-02]\n",
      " [ 5.95373407e-02]\n",
      " [ 1.87026147e-02]\n",
      " [ 7.54752827e-02]\n",
      " [ 1.83378297e-02]\n",
      " [-1.27227041e-01]\n",
      " [ 4.60572409e-02]\n",
      " [-9.25712704e-02]\n",
      " [-5.60246136e-02]\n",
      " [-1.35008169e-01]\n",
      " [-1.05130863e-01]\n",
      " [ 4.21992722e-03]\n",
      " [ 6.15338331e-03]\n",
      " [ 6.70698897e-02]\n",
      " [ 3.84599177e-02]\n",
      " [-2.31732204e-02]\n",
      " [-5.30570209e-02]\n",
      " [ 3.79193133e-03]\n",
      " [ 5.48057390e-02]\n",
      " [-4.04431186e-02]\n",
      " [-3.06737668e-03]\n",
      " [-6.23959833e-02]\n",
      " [-7.85353838e-02]\n",
      " [-2.55459854e-02]\n",
      " [-3.73880845e-02]\n",
      " [-1.70220530e-01]\n",
      " [-1.38344843e-01]\n",
      " [-2.60935347e-03]\n",
      " [-6.60811749e-02]\n",
      " [-5.46467510e-02]\n",
      " [ 1.42685111e-02]\n",
      " [-4.94324308e-02]\n",
      " [-6.54762055e-02]\n",
      " [-1.43819380e-02]\n",
      " [ 6.26237727e-02]\n",
      " [ 8.64941587e-02]\n",
      " [-4.61572176e-02]\n",
      " [-8.66236645e-02]\n",
      " [ 7.52273510e-02]\n",
      " [ 2.05215066e-01]\n",
      " [ 4.69487747e-02]\n",
      " [-5.10490373e-02]\n",
      " [-3.45982270e-02]\n",
      " [-4.19149637e-02]\n",
      " [-5.20053292e-02]\n",
      " [ 4.00126937e-02]\n",
      " [ 8.27337152e-02]\n",
      " [-5.51592100e-02]\n",
      " [ 4.40367999e-02]\n",
      " [ 5.48842116e-03]\n",
      " [-7.29701933e-02]\n",
      " [ 7.48295815e-02]\n",
      " [-1.72592742e-02]\n",
      " [ 6.26849754e-02]\n",
      " [-1.23346068e-01]\n",
      " [ 3.02817745e-02]\n",
      " [-2.93582299e-02]\n",
      " [ 7.61707153e-02]\n",
      " [-5.09961618e-02]\n",
      " [ 3.38722541e-02]\n",
      " [ 8.99066282e-02]\n",
      " [ 2.40909746e-02]\n",
      " [ 8.73166251e-03]\n",
      " [ 4.88720964e-02]\n",
      " [ 4.22349292e-03]\n",
      " [ 2.74422260e-02]\n",
      " [-1.43762145e-03]\n",
      " [-6.10309227e-02]\n",
      " [-1.79325559e-02]\n",
      " [-3.62339654e-02]\n",
      " [ 6.41439918e-02]\n",
      " [ 3.41996138e-03]\n",
      " [ 3.98311638e-02]\n",
      " [-9.34715210e-02]\n",
      " [-4.79822649e-02]\n",
      " [ 7.51742006e-03]\n",
      " [-1.72656647e-02]\n",
      " [-1.89039326e-01]\n",
      " [-3.72069824e-02]\n",
      " [-1.01650317e-01]\n",
      " [ 1.04487511e-01]\n",
      " [ 1.84900463e-01]\n",
      " [ 9.27823309e-02]\n",
      " [-4.59441482e-02]\n",
      " [ 1.33734341e-01]\n",
      " [ 2.17867453e-02]\n",
      " [-4.52466006e-02]\n",
      " [-1.00978990e-02]\n",
      " [-7.72805258e-02]\n",
      " [ 1.28217635e-02]\n",
      " [-2.20957030e-02]\n",
      " [ 1.34161459e-01]\n",
      " [-2.18174704e-02]\n",
      " [-4.46722069e-02]\n",
      " [-9.28607089e-02]\n",
      " [ 1.12390669e-01]\n",
      " [ 5.31156459e-02]\n",
      " [ 6.12867569e-03]\n",
      " [ 9.12181822e-02]\n",
      " [-2.06034493e-02]\n",
      " [-4.33361711e-02]\n",
      " [-2.17806713e-02]\n",
      " [ 3.59749745e-02]\n",
      " [-1.18401618e-01]\n",
      " [-1.97801383e-01]\n",
      " [ 3.06186354e-02]\n",
      " [-2.34876005e-02]\n",
      " [-9.48721579e-02]\n",
      " [ 6.50299411e-03]\n",
      " [-9.37153500e-02]\n",
      " [ 4.39215598e-02]\n",
      " [-5.78889482e-03]\n",
      " [-1.80580663e-01]\n",
      " [-2.75491559e-02]\n",
      " [-1.07965100e-01]\n",
      " [-6.89668848e-02]\n",
      " [ 2.60847879e-01]\n",
      " [-4.56800127e-02]\n",
      " [-2.34483757e-01]\n",
      " [-4.38847420e-02]\n",
      " [-2.36456855e-01]\n",
      " [-1.53594777e-01]\n",
      " [ 1.26027311e-01]\n",
      " [-3.89681464e-01]\n",
      " [ 2.12035164e-02]\n",
      " [-4.03046432e-02]\n",
      " [-3.14912129e-03]\n",
      " [ 3.28790833e-02]\n",
      " [-1.27622919e-01]\n",
      " [ 4.40701661e-02]\n",
      " [-6.04261590e-02]\n",
      " [ 6.62488061e-02]\n",
      " [ 3.69753262e-02]\n",
      " [ 5.45320020e-02]\n",
      " [-1.72759386e-02]\n",
      " [ 9.92861963e-02]\n",
      " [-8.95089784e-02]\n",
      " [-5.18306127e-02]\n",
      " [ 3.45366585e-02]\n",
      " [-8.27027814e-02]\n",
      " [ 1.13971363e-02]\n",
      " [ 1.52260847e-03]\n",
      " [-1.68994357e-01]\n",
      " [ 1.59808202e-01]\n",
      " [ 3.34255973e-01]\n",
      " [-2.10344375e-01]\n",
      " [-1.02365019e-01]\n",
      " [ 4.87050850e-02]\n",
      " [-3.45425663e-01]\n",
      " [ 1.45617165e-02]\n",
      " [ 4.87458818e-02]\n",
      " [-2.04695554e-02]\n",
      " [-1.07476197e-01]\n",
      " [ 5.08593913e-02]\n",
      " [ 6.54478181e-02]\n",
      " [ 3.46653342e-02]\n",
      " [-5.57253826e-02]\n",
      " [-2.92223505e-01]\n",
      " [ 4.20138068e-02]\n",
      " [-1.34298006e-01]\n",
      " [-1.85840395e-01]\n",
      " [ 4.20639093e-02]\n",
      " [-1.15576899e-02]\n",
      " [ 2.89025576e-01]\n",
      " [ 1.19934383e-01]\n",
      " [-7.68301084e-02]\n",
      " [ 6.60515855e-02]\n",
      " [-1.63339415e-02]\n",
      " [-5.07176952e-02]\n",
      " [-1.71422997e-01]\n",
      " [-4.22364084e-02]\n",
      " [ 1.03744996e-01]\n",
      " [-3.03734648e-01]\n",
      " [ 7.66438030e-02]\n",
      " [-6.41540335e-02]\n",
      " [ 2.21590626e-01]\n",
      " [-1.34438093e-02]\n",
      " [-4.78314930e-02]\n",
      " [ 2.54017204e-01]\n",
      " [ 7.07758103e-02]\n",
      " [-1.75102235e-01]\n",
      " [-2.27740011e-02]\n",
      " [-2.94949597e-02]\n",
      " [-1.64940582e-01]\n",
      " [ 1.23222246e-01]\n",
      " [ 4.78125766e-02]\n",
      " [ 7.49986641e-02]\n",
      " [-5.26685308e-02]\n",
      " [-1.74129608e-01]\n",
      " [-6.12073388e-02]\n",
      " [-1.49610076e-01]\n",
      " [ 2.61447307e-02]\n",
      " [-1.52609034e-01]\n",
      " [-1.64730353e-01]\n",
      " [-1.60170623e-01]\n",
      " [-1.32370391e-01]\n",
      " [-4.63475777e-02]\n",
      " [ 2.75202623e-03]\n",
      " [-1.47192719e-01]\n",
      " [ 2.71262390e-02]\n",
      " [ 6.81695594e-02]\n",
      " [-1.28792656e-01]\n",
      " [-7.27612361e-02]\n",
      " [-1.34628056e-01]\n",
      " [-2.05122969e-03]\n",
      " [ 1.09447495e-02]\n",
      " [ 6.91024842e-02]\n",
      " [-9.49906094e-02]\n",
      " [ 1.90202447e-02]\n",
      " [ 5.01771930e-02]\n",
      " [ 1.05481818e-01]\n",
      " [ 5.74166331e-02]\n",
      " [ 7.08675221e-02]\n",
      " [ 1.40018324e-01]\n",
      " [-2.04765455e-01]\n",
      " [-2.05895714e-01]\n",
      " [-1.22831173e-01]\n",
      " [ 6.32850465e-03]\n",
      " [-3.54198005e-02]\n",
      " [ 7.63772439e-02]\n",
      " [ 3.44744755e-02]\n",
      " [-2.91754020e-02]\n",
      " [-1.12854758e-01]\n",
      " [-4.61415865e-02]\n",
      " [-4.73503016e-02]\n",
      " [-2.23132155e-02]\n",
      " [-5.79659451e-02]\n",
      " [-3.99642012e-02]\n",
      " [-8.45883848e-02]\n",
      " [-1.16783205e-01]\n",
      " [-7.31858269e-02]\n",
      " [-1.77428601e-02]\n",
      " [-3.32915652e-02]\n",
      " [ 7.61833798e-03]\n",
      " [ 9.76920812e-02]\n",
      " [-5.78569390e-02]\n",
      " [-1.53263855e-01]\n",
      " [ 2.49198621e-02]\n",
      " [ 2.83417201e-02]\n",
      " [-4.81102239e-02]\n",
      " [ 2.31987374e-02]\n",
      " [-8.36373331e-02]\n",
      " [ 1.53048559e-01]\n",
      " [-3.63460484e-01]\n",
      " [ 1.33185341e-01]\n",
      " [-1.41310980e-02]\n",
      " [ 7.87936444e-02]\n",
      " [ 1.20385105e-01]\n",
      " [ 1.96381534e-01]\n",
      " [ 6.76463572e-02]\n",
      " [ 2.22670161e-01]\n",
      " [-3.52949453e-02]\n",
      " [ 6.04259304e-02]\n",
      " [-5.15693905e-02]\n",
      " [-7.73530849e-02]\n",
      " [-1.02811562e-02]\n",
      " [ 1.43747367e-03]\n",
      " [-5.38275779e-02]\n",
      " [-1.33379992e-01]\n",
      " [ 4.63290182e-03]\n",
      " [ 1.91484937e-02]\n",
      " [-1.85827940e-02]\n",
      " [-1.55506304e-02]\n",
      " [ 1.42148422e-01]\n",
      " [ 1.21608471e-03]\n",
      " [-6.94930534e-02]\n",
      " [ 2.58586178e-02]\n",
      " [-3.38477264e-02]\n",
      " [-4.31347578e-02]\n",
      " [-1.54508590e-01]\n",
      " [ 1.81660487e-02]\n",
      " [ 4.72191370e-03]\n",
      " [-1.49665025e-01]\n",
      " [ 2.45582407e-02]\n",
      " [-4.35280492e-02]\n",
      " [-5.13550707e-02]\n",
      " [-6.99946165e-02]\n",
      " [ 2.61835218e-02]\n",
      " [-1.46882881e-01]\n",
      " [ 1.77454297e-01]\n",
      " [-1.79230120e-02]\n",
      " [-8.01297995e-02]\n",
      " [ 1.38608145e-01]\n",
      " [-9.73505786e-02]\n",
      " [-8.10445929e-02]\n",
      " [-5.06921378e-02]\n",
      " [-2.18011323e-02]\n",
      " [ 2.19248265e-01]\n",
      " [ 2.37733426e-01]\n",
      " [-1.80001149e-01]\n",
      " [-9.08721003e-02]\n",
      " [ 6.89280869e-03]\n",
      " [-6.44224915e-02]\n",
      " [ 2.48702537e-01]\n",
      " [-2.17250254e-02]\n",
      " [ 1.54271397e-01]\n",
      " [ 8.29809687e-02]\n",
      " [ 1.34753724e-01]\n",
      " [ 1.15336903e-02]\n",
      " [ 3.48306107e-02]\n",
      " [-2.89804090e-02]\n",
      " [ 1.30866895e-02]\n",
      " [-7.04088513e-02]\n",
      " [-2.52974517e-02]\n",
      " [ 1.80023499e-01]\n",
      " [ 1.43399557e-01]\n",
      " [-2.42616469e-01]\n",
      " [-6.50443539e-02]\n",
      " [ 3.08877640e-01]\n",
      " [ 3.45741006e-01]\n",
      " [-1.71025506e-02]\n",
      " [ 3.87036564e-01]\n",
      " [ 1.39467036e-02]\n",
      " [ 2.48166453e-02]\n",
      " [-2.89653800e-01]\n",
      " [-1.05495566e-01]\n",
      " [-3.47999049e-01]\n",
      " [ 9.18399914e-02]\n",
      " [ 6.04161082e-04]\n",
      " [-1.29713191e-01]\n",
      " [ 3.44218176e-02]\n",
      " [-1.61036139e-01]\n",
      " [ 1.43413689e-02]\n",
      " [-1.63963051e-01]\n",
      " [-1.02349623e-01]\n",
      " [-9.06231012e-02]\n",
      " [ 8.87746892e-02]\n",
      " [ 4.42853772e-02]\n",
      " [-7.09925029e-02]\n",
      " [-1.87961062e-02]\n",
      " [ 1.30199917e-01]\n",
      " [-1.74136701e-01]\n",
      " [ 1.51794286e-03]\n",
      " [ 4.66418077e-02]\n",
      " [ 2.02945126e-01]\n",
      " [-1.69052806e-01]\n",
      " [-6.30548151e-02]\n",
      " [-1.07438413e-01]\n",
      " [-7.23178269e-02]\n",
      " [-1.26322146e-01]\n",
      " [ 9.53387576e-02]\n",
      " [-9.72877654e-03]\n",
      " [ 1.23479092e-01]\n",
      " [ 4.47729108e-02]\n",
      " [ 1.00100241e-01]\n",
      " [-1.13042711e-01]\n",
      " [ 7.36046332e-02]\n",
      " [ 8.45642888e-02]\n",
      " [-2.57092428e-01]\n",
      " [-8.31307239e-02]\n",
      " [-1.03066816e-01]\n",
      " [-3.34015418e-02]\n",
      " [-3.08826903e-02]\n",
      " [ 2.21151636e-01]\n",
      " [-2.48192991e-01]\n",
      " [-8.16558324e-02]\n",
      " [-1.05668765e-02]\n",
      " [ 2.75148747e-01]\n",
      " [-1.84246052e-01]\n",
      " [-9.77636818e-03]\n",
      " [-2.40867118e-02]\n",
      " [ 1.88109957e-01]\n",
      " [ 1.64629975e-02]\n",
      " [-3.62284269e-01]\n",
      " [ 1.84248698e-01]\n",
      " [ 5.78579806e-02]\n",
      " [-5.76737312e-02]\n",
      " [-1.76353015e-02]\n",
      " [-2.40359930e-01]\n",
      " [-1.38612885e-01]\n",
      " [-1.31435375e-01]\n",
      " [ 2.08319508e-02]\n",
      " [-2.49198776e-01]\n",
      " [ 1.36807385e-01]\n",
      " [ 1.84377495e-02]\n",
      " [-1.21958615e-01]\n",
      " [ 2.00854456e-02]\n",
      " [-1.08880138e-01]\n",
      " [ 3.73397707e-01]\n",
      " [-2.61245193e-01]\n",
      " [-2.34737527e-01]\n",
      " [ 1.34279328e-01]\n",
      " [-3.68592129e-01]\n",
      " [ 2.36194939e-01]\n",
      " [ 6.93251709e-02]\n",
      " [-6.59158093e-02]\n",
      " [-1.17075505e-02]\n",
      " [-5.88282824e-02]\n",
      " [ 1.90139840e-01]\n",
      " [-1.69547934e-01]\n",
      " [ 7.46512498e-02]\n",
      " [-3.09722319e-01]\n",
      " [-8.20579785e-02]\n",
      " [ 6.85307906e-03]\n",
      " [-2.27948540e-01]\n",
      " [-2.08159369e-02]\n",
      " [ 7.67308945e-02]\n",
      " [ 1.12598958e-01]\n",
      " [-1.61773050e-01]]\n"
     ]
    }
   ],
   "source": [
    "weights_for_best_model = best_k_fold_poly_ridge(X_scaled, y)\n",
    "print(weights_for_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1.0e-01 1.1e+01 7.0e+00 0.0e+00 4.0e-01 6.0e+00 7.0e+01 4.0e+00 6.0e+00\n 3.0e+02 1.6e+01 3.6e+02 1.0e+01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m scaled_feature_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m poly \u001b[38;5;241m=\u001b[39m PolynomialFeatures(degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m X_poly_feature \u001b[38;5;241m=\u001b[39m poly\u001b[38;5;241m.\u001b[39mfit_transform(feature_values[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_poly_feature\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m means \u001b[38;5;241m=\u001b[39m X_poly\u001b[38;5;241m.\u001b[39mmean(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_polynomial.py:322\u001b[0m, in \u001b[0;36mPolynomialFeatures.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    306\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m    Compute number of output features.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m        Fitted transformer.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     _, n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree, Integral):\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_bias:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    945\u001b[0m         )\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    951\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1.0e-01 1.1e+01 7.0e+00 0.0e+00 4.0e-01 6.0e+00 7.0e+01 4.0e+00 6.0e+00\n 3.0e+02 1.6e+01 3.6e+02 1.0e+01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#Scaling the given feature values\n",
    "scaled_feature_values = [1]\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_poly_feature = poly.fit_transform(feature_values[1:].reshape(len(feature_values)))\n",
    "print(X_poly_feature.shape)\n",
    "means = X_poly.mean(axis = 0)\n",
    "print(means.shape)\n",
    "standard_deviations = X_poly.std(axis = 0)\n",
    "print(standard_deviations)\n",
    "\n",
    "for i in range(1,len(X_poly_feature)):\n",
    "    scaled_feature_value = (X_poly_feature[i] - means[i]) / standard_deviations[i]\n",
    "    scaled_feature_values.append(scaled_feature_value)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features_array = np.array(scaled_feature_values).reshape(1,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = scaled_features_array @ weights_for_best_model\n",
    "print(scaled_predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = y.mean(axis=0)\n",
    "y_std = y.std(axis=0)\n",
    "\n",
    "actual_predicted_value = (scaled_predicted_value * y_std) + y_mean\n",
    "print(\"The predicted value with the given input feature values = \", actual_predicted_value[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
