{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "390cf8fd",
   "metadata": {},
   "source": [
    "# Tutorial: Polynomial Transformation, k-Fold Cross-Validation, and Feature Scaling\n",
    "\n",
    "## Table of Contents\n",
    "1. [Polynomial Transformation](#section1)\n",
    "    * Introduction\n",
    "    * Example with Code\n",
    "    * Bias Parameter Explanation\n",
    "    \n",
    "2. [k-Fold Cross-Validation](#section2)\n",
    "    * Introduction\n",
    "    * Mathematical Explanation\n",
    "    * Example with Code\n",
    "    \n",
    "3. [Standard Scaler: How it Works](#section3)\n",
    "    * Introduction\n",
    "    * Mathematical Explanation\n",
    "    * Example with Code\n",
    "\n",
    "---\n",
    "\n",
    "<a id='section1'></a>\n",
    "## 1. Polynomial Transformation\n",
    "### Introduction\n",
    "Polynomial transformation is a technique to introduce higher degree features into the dataset, making our linear model capable of fitting non-linear relationships.\n",
    "\n",
    "`PolynomialFeatures` is a pre-processing technique used for feature engineering. It generates a new feature matrix consisting of all polynomial combinations of the original features up to a specified degree. For a feature vector `x = [a, b]` of degree `2`, the output is `[1, a, b, a^2, ab, b^2]`.\n",
    "\n",
    "### Example with Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e204d6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  4.  4.  8. 16.]\n",
      " [ 1.  3.  5.  9. 15. 25.]\n",
      " [ 1.  1.  8.  1.  8. 64.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generate a simple synthetic dataset\n",
    "X = np.array([[2,4], [3,5], [1,8]])\n",
    "\n",
    "# Instantiate the PolynomialFeatures class with degree=2\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "# Transform the data to include polynomial features and a bias column (column of ones)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Display the transformed data\n",
    "print(X_poly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b8921f",
   "metadata": {},
   "source": [
    "### Bias in Polynomial Features\n",
    "\n",
    "In polynomial regression, a bias term is often included, $x_0=1$.\n",
    "\n",
    "In the `PolynomialFeatures()` function, this bias term is controlled by the `include_bias` parameter. When set to `True` (which is its default setting), a bias column is added to the output. This column is uniformly filled with ones. Conceptually, for each data sample, this is akin to having an additional feature \\(x_0 = 1\\).\n",
    "\n",
    "\n",
    "However, there may be times when you'd prefer to not include this bias term. To turn off the bias term in `PolynomialFeatures()`, you can set the `include_bias` parameter to `False`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d87ee",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## 2. k-Fold Cross-Validation\n",
    "\n",
    "### Introduction\n",
    "k-Fold cross-validation involves dividing the dataset into 'k' subsets. The model is trained on \\(k-1\\) of these folds and validated on the remaining 1 fold. This process is repeated 'k' times, each time with a different fold as the validation set.\n",
    "\n",
    "###  Explanation\n",
    "Let's denote our dataset as $D$, which we divide into $k$ folds, \\( $D_1$, $D_2$, ... , $D_k$ \\). For each fold $i$:\n",
    "1. Train the model on \\( $D$ - $D_i$ \\) (all data except the ith fold)\n",
    "2. Validate the model on \\( $D_i$ \\)\n",
    "\n",
    "After k iterations, average the performance across all folds to get a final model performance measure.\n",
    "\n",
    "### Example with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fa6bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [1 2] Validation: [0]\n",
      "Train: [0 2] Validation: [1]\n",
      "Train: [0 1] Validation: [2]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary module from scikit-learn to perform K-fold cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create an instance of KFold class specifying the number of splits (folds)\n",
    "# In this example, we are using 3 folds for our cross-validation\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "# Iterate through each fold using the split method provided by the KFold object.\n",
    "# The split method returns indices for the train and test (validation) sets for each fold.\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"Train:\", train_index, \"Validation:\", test_index)\n",
    "    \n",
    "    # Using the indices provided, we split our dataset (both features and target) \n",
    "    # into training and validation sets for the current fold.\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # --- Placeholder for model-specific steps ---\n",
    "    # 1. Fit the model using X_train and y_train\n",
    "    # 2. Predict on X_test\n",
    "    # 3. Compute the error between y_test and the predictions\n",
    "    # 4. Save the computed error for later analysis\n",
    "\n",
    "# After looping through all folds, compute and display the average error (assuming errors are saved in a list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba182c",
   "metadata": {},
   "source": [
    "### Shuffling the Data\n",
    "By default, `KFold` does not shuffle the dataset before splitting. However, if you want the data to be shuffled before forming the folds, you can set the `shuffle` parameter to `True` during the `KFold` initialization. Additionally, setting a `random_state` ensures the shuffle produces the same result across different runs, maintaining reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1029ef8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [1 2] Validation: [0]\n",
      "Train: [0 2] Validation: [1]\n",
      "Train: [0 1] Validation: [2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"Train:\", train_index, \"Validation:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c430871b",
   "metadata": {},
   "source": [
    "## 3. Standard Scaler: How it Works\n",
    "\n",
    "### Introduction\n",
    "\n",
    "`StandardScaler` standardizes the datasetâ€™s features by removing the mean and scaling them to unit variance. \n",
    "\n",
    "### Mathematical Explanation\n",
    "\n",
    "Given a feature \\( x \\), the standard scaler applies:\n",
    "\n",
    "$x' = \\frac{x - \\text{mean}(x)}{\\text{std}(x)} $\n",
    "\n",
    "Where:\n",
    "- $ x' $ is the transformed feature\n",
    "- $\\text{mean}(x) $ is the mean of feature $ x $\n",
    "- $ \\text{std}(x) $ is its standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32a9add8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.98058068]\n",
      " [ 1.22474487 -0.39223227]\n",
      " [-1.22474487  1.37281295]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df385eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
